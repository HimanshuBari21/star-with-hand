<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hand Controlled Star Field</title>
    <style>
        body {
            margin: 0;
            overflow: hidden;
            background-color: #000000; /* Dark black background */
            font-family: sans-serif;
        }
        #video-container {
            position: absolute;
            top: 20px;
            left: 20px;
            width: 160px;
            height: 120px;
            border: 2px solid #333;
            border-radius: 8px;
            overflow: hidden;
            z-index: 10;
            opacity: 0.7;
        }
        #input_video {
            width: 100%;
            height: 100%;
            transform: scaleX(-1); /* Mirror the webcam preview */
            object-fit: cover;
        }
        #canvas-container {
            width: 100vw;
            height: 100vh;
        }
        #loading {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            color: white;
            pointer-events: none;
            z-index: 20;
        }
    </style>
</head>
<body>

    <div id="loading">Initializing Camera & AI...</div>

    <div id="video-container">
        <video id="input_video"></video>
    </div>

    <div id="canvas-container"></div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/control_utils/control_utils.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js" crossorigin="anonymous"></script>

    <script>
        // --- 1. THREE.JS SETUP (The Visuals) ---
        const scene = new THREE.Scene();
        // Fog to fade distant stars into the black background
        scene.fog = new THREE.FogExp2(0x000000, 0.002);

        const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
        camera.position.z = 50;

        const renderer = new THREE.WebGLRenderer({ antialias: true });
        renderer.setSize(window.innerWidth, window.innerHeight);
        renderer.setPixelRatio(window.devicePixelRatio);
        document.getElementById('canvas-container').appendChild(renderer.domElement);

        // Create Stars
        const starGeometry = new THREE.BufferGeometry();
        const starCount = 6000;
        const posArray = new Float32Array(starCount * 3);

        for(let i = 0; i < starCount * 3; i++) {
            // Spread stars randomly in a large area
            posArray[i] = (Math.random() - 0.5) * 200; 
        }

        starGeometry.setAttribute('position', new THREE.BufferAttribute(posArray, 3));

        const starMaterial = new THREE.PointsMaterial({
            size: 0.5,
            color: 0xffffff,
            transparent: true,
            opacity: 0.8,
        });

        const starMesh = new THREE.Points(starGeometry, starMaterial);
        scene.add(starMesh);

        // --- 2. INTERACTION STATE ---
        let targetRotationX = 0;
        let targetRotationY = 0;
        
        // --- 3. MEDIAPIPE SETUP (The Hand Tracking) ---
        const videoElement = document.getElementById('input_video');
        const loadingElement = document.getElementById('loading');

        function onResults(results) {
            loadingElement.style.display = 'none';

            if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
                // Get the first detected hand
                const landmarks = results.multiHandLandmarks[0];
                
                // Use the wrist (landmark 0) or middle finger (landmark 9) as the control point
                // Landmarks are normalized (0.0 to 1.0)
                const x = landmarks[9].x; 
                const y = landmarks[9].y;

                // Map coordinates to rotation angles
                // MediaPipe x is 0(left) to 1(right). 
                // We offset by -0.5 to make center 0.
                // Multiplier determines sensitivity.
                targetRotationY = (x - 0.5) * 4; 
                targetRotationX = (y - 0.5) * 4; 
            }
        }

        const hands = new Hands({locateFile: (file) => {
            return `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`;
        }});

        hands.setOptions({
            maxNumHands: 1,
            modelComplexity: 1,
            minDetectionConfidence: 0.5,
            minTrackingConfidence: 0.5
        });

        hands.onResults(onResults);

        const cameraFeed = new Camera(videoElement, {
            onFrame: async () => {
                await hands.send({image: videoElement});
            },
            width: 320,
            height: 240
        });

        cameraFeed.start();

        // --- 4. ANIMATION LOOP ---
        function animate() {
            requestAnimationFrame(animate);

            // Smooth interpolation (Lerp) for fluid movement
            // This makes the stars "glide" to the hand position rather than snap instantly
            starMesh.rotation.y += (targetRotationY - starMesh.rotation.y) * 0.05;
            starMesh.rotation.x += (targetRotationX - starMesh.rotation.x) * 0.05;

            // Add a tiny bit of constant rotation for idle visual interest
            starMesh.rotation.z += 0.001;

            renderer.render(scene, camera);
        }

        animate();

        // Handle window resize
        window.addEventListener('resize', () => {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        });

    </script>
</body>
</html>